{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeea689c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Obtaining dependency information for ucimlrepo from https://files.pythonhosted.org/packages/22/47/9350b2eeeaef8c0fd3ec3505c8a0481b576845b3df0d71c76f989c23d3c6/ucimlrepo-0.0.6-py3-none-any.whl.metadata\n",
      "  Downloading ucimlrepo-0.0.6-py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.6\n"
     ]
    }
   ],
   "source": [
    "# First installing this for dataset\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44888cb1",
   "metadata": {},
   "source": [
    "Here, we utilized the Spambase dataset from the UCI Machine Learning Repository to build and evaluate models for classifying emails as spam or ham (non-spam).\n",
    "\n",
    "First, we fetched and split the dataset into training and testing sets, then standardized the features. We trained two machine learning models: Logistic Regression and Random Forest. After training, we evaluated the models using accuracy scores and classification reports to measure their performance.\n",
    "\n",
    "Finally, we created a function to predict whether new emails are spam or ham using these trained models and tested this function with example email data for both spam and ham. This process demonstrates a practical approach to email classification using machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b6fa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n",
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75df5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2245d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data (features and targets) as pandas DataFrames\n",
    "X = spambase.data.features\n",
    "y = spambase.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2bb7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696428f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3486d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadia\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Sadia\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train a Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Initialize and train a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca49dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class of the test set using all models\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "rf_pred = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e7027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "lr_report = classification_report(y_test, lr_pred)\n",
    "rf_report = classification_report(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "109dfe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.93\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       837\n",
      "           1       0.92      0.90      0.91       544\n",
      "\n",
      "    accuracy                           0.93      1381\n",
      "   macro avg       0.93      0.92      0.93      1381\n",
      "weighted avg       0.93      0.93      0.93      1381\n",
      "\n",
      "Random Forest Accuracy: 0.96\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       837\n",
      "           1       0.96      0.93      0.94       544\n",
      "\n",
      "    accuracy                           0.96      1381\n",
      "   macro avg       0.96      0.95      0.95      1381\n",
      "weighted avg       0.96      0.96      0.96      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation results\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy:.2f}')\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(lr_report)\n",
    "\n",
    "print(f'Random Forest Accuracy: {rf_accuracy:.2f}')\n",
    "print('Random Forest Classification Report:')\n",
    "print(rf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b02f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict if a new email is spam or ham using all models\n",
    "def predict_spam_or_ham(new_data):\n",
    "    # Ensure the new data is in the correct format (DataFrame)\n",
    "    if isinstance(new_data, dict):\n",
    "        new_data = pd.DataFrame([new_data])\n",
    "    elif isinstance(new_data, list):\n",
    "        new_data = pd.DataFrame(new_data)\n",
    "\n",
    "    # Standardize the new data using the same scaler\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "    # Predict using the trained models\n",
    "    lr_prediction = lr_model.predict(new_data_scaled)\n",
    "    rf_prediction = rf_model.predict(new_data_scaled)\n",
    "\n",
    "    # Map the predictions to human-readable labels\n",
    "    predictions = {\n",
    "        'Logistic Regression': ['Spam' if pred == 1 else 'Ham' for pred in lr_prediction],\n",
    "        'Random Forest': ['Spam' if pred == 1 else 'Ham' for pred in rf_prediction]\n",
    "    }\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc015f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Email Predictions:\n",
      "{'Logistic Regression': ['Spam'], 'Random Forest': ['Spam']}\n",
      "Ham Email Predictions:\n",
      "{'Logistic Regression': ['Ham'], 'Random Forest': ['Ham']}\n"
     ]
    }
   ],
   "source": [
    "# Example new data for spam prediction (Here we can  replace with actual new email data but for now we are using exmaple data)\n",
    "spam_email_data = {\n",
    "    'word_freq_make': 0.21, 'word_freq_address': 0.0, 'word_freq_all': 0.28, 'word_freq_3d': 0.0, 'word_freq_our': 0.18,\n",
    "    'word_freq_over': 0.0, 'word_freq_remove': 0.36, 'word_freq_internet': 0.0, 'word_freq_order': 0.0, 'word_freq_mail': 0.0,\n",
    "    'word_freq_receive': 0.0, 'word_freq_will': 0.0, 'word_freq_people': 0.0, 'word_freq_report': 0.0, 'word_freq_addresses': 0.0,\n",
    "    'word_freq_free': 0.42, 'word_freq_business': 0.0, 'word_freq_email': 0.0, 'word_freq_you': 0.18, 'word_freq_credit': 0.0,\n",
    "    'word_freq_your': 0.37, 'word_freq_font': 0.0, 'word_freq_000': 0.0, 'word_freq_money': 0.42, 'word_freq_hp': 0.0,\n",
    "    'word_freq_hpl': 0.0, 'word_freq_george': 0.0, 'word_freq_650': 0.0, 'word_freq_lab': 0.0, 'word_freq_labs': 0.0,\n",
    "    'word_freq_telnet': 0.0, 'word_freq_857': 0.0, 'word_freq_data': 0.0, 'word_freq_415': 0.0, 'word_freq_85': 0.0,\n",
    "    'word_freq_technology': 0.0, 'word_freq_1999': 0.0, 'word_freq_parts': 0.0, 'word_freq_pm': 0.0, 'word_freq_direct': 0.0,\n",
    "    'word_freq_cs': 0.0, 'word_freq_meeting': 0.0, 'word_freq_original': 0.0, 'word_freq_project': 0.0, 'word_freq_re': 0.0,\n",
    "    'word_freq_edu': 0.0, 'word_freq_table': 0.0, 'word_freq_conference': 0.0, 'char_freq_;': 0.0, 'char_freq_(': 0.0,\n",
    "    'char_freq_[': 0.0, 'char_freq_!': 0.77, 'char_freq_$': 0.0, 'char_freq_#': 0.0, 'capital_run_length_average': 1.8,\n",
    "    'capital_run_length_longest': 4, 'capital_run_length_total': 10\n",
    "}\n",
    "\n",
    "# Example new data for ham prediction (Here we can replace with actual new email data but for now we are using exmaple data)\n",
    "ham_email_data = {\n",
    "    'word_freq_make': 0.0, 'word_freq_address': 0.0, 'word_freq_all': 0.0, 'word_freq_3d': 0.0, 'word_freq_our': 0.0,\n",
    "    'word_freq_over': 0.0, 'word_freq_remove': 0.0, 'word_freq_internet': 0.0, 'word_freq_order': 0.0, 'word_freq_mail': 0.0,\n",
    "    'word_freq_receive': 0.0, 'word_freq_will': 0.21, 'word_freq_people': 0.0, 'word_freq_report': 0.0, 'word_freq_addresses': 0.0,\n",
    "    'word_freq_free': 0.0, 'word_freq_business': 0.0, 'word_freq_email': 0.0, 'word_freq_you': 0.18, 'word_freq_credit': 0.0,\n",
    "    'word_freq_your': 0.19, 'word_freq_font': 0.0, 'word_freq_000': 0.0, 'word_freq_money': 0.0, 'word_freq_hp': 0.0,\n",
    "    'word_freq_hpl': 0.0, 'word_freq_george': 0.15, 'word_freq_650': 0.06, 'word_freq_lab': 0.0, 'word_freq_labs': 0.0,\n",
    "    'word_freq_telnet': 0.0, 'word_freq_857': 0.0, 'word_freq_data': 0.0, 'word_freq_415': 0.06, 'word_freq_85': 0.0,\n",
    "    'word_freq_technology': 0.0, 'word_freq_1999': 0.0, 'word_freq_parts': 0.0, 'word_freq_pm': 0.0, 'word_freq_direct': 0.0,\n",
    "    'word_freq_cs': 0.0, 'word_freq_meeting': 0.0, 'word_freq_original': 0.0, 'word_freq_project': 0.0, 'word_freq_re': 0.0,\n",
    "    'word_freq_edu': 0.32, 'word_freq_table': 0.0, 'word_freq_conference': 0.0, 'char_freq_;': 0.02, 'char_freq_(': 0.02,\n",
    "    'char_freq_[': 0.0, 'char_freq_!': 0.0, 'char_freq_$': 0.0, 'char_freq_#': 0.0, 'capital_run_length_average': 0.28,\n",
    "    'capital_run_length_longest': 3, 'capital_run_length_total': 9\n",
    "}\n",
    "\n",
    "# Predict if the new emails are spam or ham\n",
    "spam_predictions = predict_spam_or_ham(spam_email_data)\n",
    "ham_predictions = predict_spam_or_ham(ham_email_data)\n",
    "\n",
    "print('Spam Email Predictions:')\n",
    "print(spam_predictions)\n",
    "\n",
    "print('Ham Email Predictions:')\n",
    "print(ham_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f86360",
   "metadata": {},
   "source": [
    "Both the Logistic Regression and Random Forest classifiers have demonstrated high accuracy in classifying emails as spam or ham on the Spambase dataset. Logistic Regression achieved an accuracy of 93%, with precision, recall, and F1-scores ranging from 0.91 to 0.94 for both classes.\n",
    "\n",
    "Meanwhile, the Random Forest classifier achieved an even higher accuracy of 96%, with similar precision, recall, and F1-scores between 0.94 and 0.96 for both classes. These results indicate that both models perform well in distinguishing between spam and ham emails, with the Random Forest classifier slightly outperforming Logistic Regression in terms of overall accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
