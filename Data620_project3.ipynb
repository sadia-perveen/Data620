{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7900cb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dev-test dataset: 0.786\n",
      "Accuracy on the testing dataset: 0.744\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "from nltk.classify import apply_features\n",
    "\n",
    "# Combine male and female names and assign labels\n",
    "combined_names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "                  [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(combined_names)\n",
    "\n",
    "# Split data into training, dev-test, and test subsets\n",
    "training_data = combined_names[1000:]\n",
    "devtest_data = combined_names[500:1000]\n",
    "testing_data = combined_names[:500]\n",
    "\n",
    "# Define a function to extract relevant features from names\n",
    "def extract_features(name):\n",
    "    return {'last_char': name[-1].lower()}\n",
    "\n",
    "# Apply feature extraction to the datasets\n",
    "training_features = apply_features(extract_features, training_data)\n",
    "devtest_features = apply_features(extract_features, devtest_data)\n",
    "testing_features = apply_features(extract_features, testing_data)\n",
    "\n",
    "# Train a Naive Bayes Classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_features)\n",
    "\n",
    "# Evaluate and print the classifier's accuracy on the dev-test data\n",
    "accuracy_devtest = nltk.classify.accuracy(classifier, devtest_features)\n",
    "print(f\"Accuracy on the dev-test dataset: {accuracy_devtest}\")\n",
    "\n",
    "# Conduct an error analysis\n",
    "errors = []\n",
    "for (name, actual_label) in combined_names[500:1000]:\n",
    "    predicted_label = classifier.classify(extract_features(name))\n",
    "    if predicted_label != actual_label:\n",
    "        errors.append((actual_label, predicted_label, name))\n",
    "\n",
    "# Evaluate and print the classifier's accuracy on the unseen test data\n",
    "accuracy_test = nltk.classify.accuracy(classifier, testing_features)\n",
    "print(f\"Accuracy on the testing dataset: {accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1511cefd",
   "metadata": {},
   "source": [
    "### How does the performance on the test set compare to the performance on the dev-test set? Is this what \n",
    "you'd expect?When we look at how well the classifier works, we notice it does a bit better on the dev-test set (77.2% accuracy) than on the test set (74.8% accuracy). This is something we often see and expect.\n",
    "\n",
    "Here's why this makes sen and is expectedse:\n",
    "\n",
    "Getting Used to the Data: We use the dev-test set to tweak and improve our classifier. It's like the classifier gets a bit familiar with this data, even though we're not directly training it on this data. So, it tends to do a bit better here than on totally new data.\n",
    "\n",
    "Overfitting: If we keep trying to make our classifier perform better on the dev-test set by changing it a lot, it might start picking up random patterns that don't really matter (this is called overfitting). This can make it do well on data it's seen (like the dev-test set) but not so well on new data.\n",
    "\n",
    "New Stuff is Tricky: The test set is completely new to the classifier. Since it hasn't seen this data before, it's a good test to see how well the classifier can handle new information. It's pretty normal for the accuracy to dip a bit on this new set.\n",
    "\n",
    "So, seeing a bit of a drop in how well the classifier works on new data (the test set) compared to the dev-test set is expected. It's a good reminder of why we need to test our classifiers on new, unseen data to really understand how well they can do.abilities. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
